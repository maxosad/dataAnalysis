{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Fraudulent claims in Banksim\n",
    "This notebook tries to create a supervised learning model to detect fraudulent transactions in the BankSim dataset provided by https://www.kaggle.com/ntnu-testimon/banksim1 \n",
    "\n",
    "The goal is to first create a benchmark model on the intrinsic features provided, the dataset will then be modeled as a graph using a Neo4j database to be able to apply graph theory algorithms in order of creating network features to feed into the model. \n",
    "\n",
    "### Implementation steps\n",
    "The steps for creating the model are as follows:  \n",
    "1. Preprocess data to be able to feed into predictive model\n",
    " 1. Remove rows with empty values\n",
    " 2. Normalize feature values\n",
    "2. Train supervised learning model\n",
    " 1. Split data into 5 folds, to use for cross validation\n",
    " 2. Estimate model prediction error using K-fold cross validation\n",
    " 3. Choose best performing model\n",
    " 4. Optimize hyperparameters using grid search\n",
    "3. Measure performance of final optimized model %on intrinsic features\n",
    "4. Create graph data model \n",
    "5. Apply graph algorithms to create network features\n",
    "6. Add network features to preprocessed dataset from step 1\n",
    "7. Retrain supervised learning model with additional features using same method from step 2\n",
    "8. Measure performance of model with network features and compare to metrics from step 3\n",
    "9. Quantify performance gains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "This section will provide some basic exploration of the dataset in question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>customer</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>zipcodeOri</th>\n",
       "      <th>merchant</th>\n",
       "      <th>zipMerchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>'C1093826151'</td>\n",
       "      <td>'4'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>'C352968107'</td>\n",
       "      <td>'2'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>39.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>'C2054744914'</td>\n",
       "      <td>'4'</td>\n",
       "      <td>'F'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M1823072687'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>26.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>'C1760612790'</td>\n",
       "      <td>'3'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>17.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>'C757503768'</td>\n",
       "      <td>'5'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>35.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step       customer  age gender zipcodeOri       merchant zipMerchant  \\\n",
       "0     0  'C1093826151'  '4'    'M'    '28007'   'M348934600'     '28007'   \n",
       "1     0   'C352968107'  '2'    'M'    '28007'   'M348934600'     '28007'   \n",
       "2     0  'C2054744914'  '4'    'F'    '28007'  'M1823072687'     '28007'   \n",
       "3     0  'C1760612790'  '3'    'M'    '28007'   'M348934600'     '28007'   \n",
       "4     0   'C757503768'  '5'    'M'    '28007'   'M348934600'     '28007'   \n",
       "\n",
       "              category  amount  fraud  \n",
       "0  'es_transportation'    4.55      0  \n",
       "1  'es_transportation'   39.68      0  \n",
       "2  'es_transportation'   26.89      0  \n",
       "3  'es_transportation'   17.25      0  \n",
       "4  'es_transportation'   35.72      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bs140513_032310.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the data consists of 10 fields, 9 input features and one label noting if the datapoint is fraudulent or not\n",
    "\n",
    "### Number of unique values\n",
    "Exploring how many unique values there are for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Number of unique values per feature ----------\n",
      " |step: 180|  |customer: 4112|  |age: 8|  |gender: 4|  |zipcodeOri: 1|  |merchant: 50|  |zipMerchant: 1|  |category: 15|  |amount: 23767|  |fraud: 2| \n"
     ]
    }
   ],
   "source": [
    "unique_print_str =  \"\"\n",
    "for column in df:\n",
    "    unique_print_str += \" |{}: {}| \".format(column, df[column].unique().size)\n",
    "    #print(df[column].unique().size)\n",
    "print('---------- Number of unique values per feature ----------')\n",
    "print(unique_print_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the zipcodeOri and zipMerchant features contain only one unique value. \n",
    "\n",
    "### Amount of fraudulent nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of datapoints are 594643\n",
      "The number of non-fraudulent datapoints are 587443, equal to 98.79 % of the dataset\n",
      "The number of fraudulent datapoints are 7200, equal to 1.21 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "total = df.shape[0]\n",
    "normal = df[df.fraud == 0].step.count()\n",
    "fraudulent = total - normal\n",
    "\n",
    "print(\"The total number of datapoints are {}\".format(total))\n",
    "print(\"The number of non-fraudulent datapoints are {}, equal to {} % of the dataset\".format(normal, round(100 *normal/total, 2)))\n",
    "print(\"The number of fraudulent datapoints are {}, equal to {} % of the dataset\".format(fraudulent, round(100 *fraudulent/total,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>customer</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>zipcodeOri</th>\n",
       "      <th>merchant</th>\n",
       "      <th>zipMerchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>'C1093826151'</td>\n",
       "      <td>'4'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>'C352968107'</td>\n",
       "      <td>'2'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>39.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>'C2054744914'</td>\n",
       "      <td>'4'</td>\n",
       "      <td>'F'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M1823072687'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>26.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>'C1760612790'</td>\n",
       "      <td>'3'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>17.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>'C757503768'</td>\n",
       "      <td>'5'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>35.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step       customer  age gender zipcodeOri       merchant zipMerchant  \\\n",
       "0     0  'C1093826151'  '4'    'M'    '28007'   'M348934600'     '28007'   \n",
       "1     0   'C352968107'  '2'    'M'    '28007'   'M348934600'     '28007'   \n",
       "2     0  'C2054744914'  '4'    'F'    '28007'  'M1823072687'     '28007'   \n",
       "3     0  'C1760612790'  '3'    'M'    '28007'   'M348934600'     '28007'   \n",
       "4     0   'C757503768'  '5'    'M'    '28007'   'M348934600'     '28007'   \n",
       "\n",
       "              category  amount  \n",
       "0  'es_transportation'    4.55  \n",
       "1  'es_transportation'   39.68  \n",
       "2  'es_transportation'   26.89  \n",
       "3  'es_transportation'   17.25  \n",
       "4  'es_transportation'   35.72  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the features and labels\n",
    "label = df.fraud\n",
    "features = df.drop('fraud', axis = 1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "When some basic data exploring has been done, the data needs to be preprocessed to be able to be used as input features of the supervised learning models. \n",
    "### Removing empty values and non-usable features\n",
    "As a first preprocessing step, empty values in the dataset should be handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if empty values...\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dataset does not contain any empty values, no rows will be removed from the dataset. \n",
    "\n",
    "Secondly, the features step, zipcodeOri, zipMerchant and customer will be removed. The zip codes are removed since they only contain one unique value. The customer so the model won't overfit on the customer name but to be able to learn to predict even new customers. The step is removed since this model won't .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'4'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'2'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>39.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'4'</td>\n",
       "      <td>'F'</td>\n",
       "      <td>'M1823072687'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>26.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'3'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>17.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'5'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>35.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age gender       merchant             category  amount\n",
       "0  '4'    'M'   'M348934600'  'es_transportation'    4.55\n",
       "1  '2'    'M'   'M348934600'  'es_transportation'   39.68\n",
       "2  '4'    'F'  'M1823072687'  'es_transportation'   26.89\n",
       "3  '3'    'M'   'M348934600'  'es_transportation'   17.25\n",
       "4  '5'    'M'   'M348934600'  'es_transportation'   35.72"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features =  features.drop(['step','zipcodeOri', 'zipMerchant', 'customer'], axis = 1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Numerical Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'4'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>0.000546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'2'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>0.004764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'4'</td>\n",
       "      <td>'F'</td>\n",
       "      <td>'M1823072687'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>0.003228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'3'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>0.002071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'5'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>0.004288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age gender       merchant             category    amount\n",
       "0  '4'    'M'   'M348934600'  'es_transportation'  0.000546\n",
       "1  '2'    'M'   'M348934600'  'es_transportation'  0.004764\n",
       "2  '4'    'F'  'M1823072687'  'es_transportation'  0.003228\n",
       "3  '3'    'M'   'M348934600'  'es_transportation'  0.002071\n",
       "4  '5'    'M'   'M348934600'  'es_transportation'  0.004288"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df[['amount', 'fraud']] = scaler.fit_transform(df[['amount', 'fraud']])\n",
    "features.amount = df.amount\n",
    "\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting categorical values using one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_final = pd.get_dummies(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>age_'0'</th>\n",
       "      <th>age_'1'</th>\n",
       "      <th>age_'2'</th>\n",
       "      <th>age_'3'</th>\n",
       "      <th>age_'4'</th>\n",
       "      <th>age_'5'</th>\n",
       "      <th>age_'6'</th>\n",
       "      <th>age_'U'</th>\n",
       "      <th>gender_'E'</th>\n",
       "      <th>...</th>\n",
       "      <th>category_'es_home'</th>\n",
       "      <th>category_'es_hotelservices'</th>\n",
       "      <th>category_'es_hyper'</th>\n",
       "      <th>category_'es_leisure'</th>\n",
       "      <th>category_'es_otherservices'</th>\n",
       "      <th>category_'es_sportsandtoys'</th>\n",
       "      <th>category_'es_tech'</th>\n",
       "      <th>category_'es_transportation'</th>\n",
       "      <th>category_'es_travel'</th>\n",
       "      <th>category_'es_wellnessandbeauty'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000546</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004764</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     amount  age_'0'  age_'1'  age_'2'  age_'3'  age_'4'  age_'5'  age_'6'  \\\n",
       "0  0.000546        0        0        0        0        1        0        0   \n",
       "1  0.004764        0        0        1        0        0        0        0   \n",
       "2  0.003228        0        0        0        0        1        0        0   \n",
       "3  0.002071        0        0        0        1        0        0        0   \n",
       "4  0.004288        0        0        0        0        0        1        0   \n",
       "\n",
       "   age_'U'  gender_'E'  ...  category_'es_home'  category_'es_hotelservices'  \\\n",
       "0        0           0  ...                   0                            0   \n",
       "1        0           0  ...                   0                            0   \n",
       "2        0           0  ...                   0                            0   \n",
       "3        0           0  ...                   0                            0   \n",
       "4        0           0  ...                   0                            0   \n",
       "\n",
       "   category_'es_hyper'  category_'es_leisure'  category_'es_otherservices'  \\\n",
       "0                    0                      0                            0   \n",
       "1                    0                      0                            0   \n",
       "2                    0                      0                            0   \n",
       "3                    0                      0                            0   \n",
       "4                    0                      0                            0   \n",
       "\n",
       "   category_'es_sportsandtoys'  category_'es_tech'  \\\n",
       "0                            0                   0   \n",
       "1                            0                   0   \n",
       "2                            0                   0   \n",
       "3                            0                   0   \n",
       "4                            0                   0   \n",
       "\n",
       "   category_'es_transportation'  category_'es_travel'  \\\n",
       "0                             1                     0   \n",
       "1                             1                     0   \n",
       "2                             1                     0   \n",
       "3                             1                     0   \n",
       "4                             1                     0   \n",
       "\n",
       "   category_'es_wellnessandbeauty'  \n",
       "0                                0  \n",
       "1                                0  \n",
       "2                                0  \n",
       "3                                0  \n",
       "4                                0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(594643, 78)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Standard Models \n",
    "When all features has been preprocessed, two models (a Random Forest and a SVC) trained on the standard features will be compared to each other using K-Fold Cross Validation to find the model best suited for the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import * \n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "fold_betas = []\n",
    "fold_accuracy = []\n",
    "kf.get_n_splits(features_final)\n",
    "\n",
    "for train_index, test_index in kf.split(features_final):\n",
    "    X_train, X_test = features_final.iloc[train_index], features_final.iloc[test_index]\n",
    "    y_train, y_test = label.iloc[train_index], label.iloc[test_index]\n",
    "    \n",
    "    clfSVM = SVC()\n",
    "    clfSVM.fit(X_train,y_train)\n",
    "    clfRandomForest = RandomForestClassifier()\n",
    "    clfRandomForest.fit(X_train,y_train)\n",
    "    \n",
    "    predictionsSVM = clfSVM.predict(X_test)\n",
    "    predictionsRF = clfRandomForest.predict(X_test)\n",
    "    \n",
    "    fold_betas.append({\"SVM\": fbeta_score( y_test, predictionsSVM, average='macro', beta=1),\n",
    "                       \"RF\": fbeta_score( y_test, predictionsRF, average='macro', beta=1) })\n",
    "    fold_accuracy.append({\"SVM\": accuracy_score( y_test, predictionsSVM),\n",
    "                       \"RF\": accuracy_score(y_test, predictionsRF) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_for_fold(fold_data, model_names):\n",
    "    model_1_sum = 0\n",
    "    model_2_sum = 0\n",
    "\n",
    "    for dat in fold_data:\n",
    "        model_1_sum += dat[model_names[0]]/len(fold_data)\n",
    "        model_2_sum += dat[model_names[1]]/len(fold_data)\n",
    "\n",
    "    print(\"Model {} average: {}\".format(model_names[0], model_1_sum))\n",
    "    print(\"Model {} average: {}\".format(model_names[1], model_2_sum))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- Betas Average ----------\")\n",
    "calculate_average_for_fold(fold_betas, [\"SVM\", \"RF\"])\n",
    "print(\"---------- Accuracy Averages -----------\")\n",
    "calculate_average_for_fold(fold_accuracy, [\"SVM\", \"RF\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization\n",
    "As seen above, the Random Forest outperformes the SVC model in both f_1 score and accuracy. Therefore, the hyperparameters of the Random Forest model will be optimized using Grid Search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final, \n",
    "                                                    label, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf2 = RandomForestClassifier()\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf2.predict(X_test)\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune, using a dictionary if needed.\n",
    "# HINT: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\n",
    "parameters = {'n_estimators': [5, 10 , 100],\n",
    "              'min_samples_split': [2, 10, 50],\n",
    "              'max_features': [\"sqrt\", \"log2\"],\n",
    "             }\n",
    "\n",
    "# TODO: Make an fbeta_score scoring object using make_scorer()\n",
    "scorer = make_scorer(fbeta_score, beta=1)\n",
    "\n",
    "# TODO: Perform grid search on the classifier using 'scorer' as the scoring method using GridSearchCV()\n",
    "grid_obj = GridSearchCV(clf, param_grid=parameters, scoring=scorer)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 1)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 1))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Features\n",
    "The following network features have been computed for both the customer and the merchant: Degree, PageRank and Community. These network features will be added to the dataset and preprocessed before used to train a Random Forest model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "\n",
    "graph = Graph(password=\"password123\", bolt_port=11002, http_port=11001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cypher query to get data from all the nodes \n",
    "query = \"\"\"\n",
    "MATCH (p:Placeholder)\n",
    "RETURN p.id AS id, p.degree AS degree, p.pagerank as pagerank, p.community AS community \n",
    "\"\"\"\n",
    "\n",
    "data = graph.run(query)\n",
    "valueDict = {}\n",
    "for d in data:\n",
    "    valueDict[d['id']] = {'degree': d['degree'], 'pagerank': d['pagerank'], 'community': d['community']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to add network features to input dataframe \n",
    "def add_degree(x):\n",
    "    return valueDict[x.split(\"'\")[1]]['degree']\n",
    "def add_community(x):\n",
    "    return str(valueDict[x.split(\"'\")[1]]['community']) # cast to string for one-hot encoding\n",
    "def add_pagerank(x):\n",
    "    return valueDict[x.split(\"'\")[1]]['pagerank']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a new dataframe and add netork features \n",
    "df = pd.read_csv(\"/Users/victorode/Developer/Python/Neo4j/Neo4jProject/Fraud Detection Model/data/bs140513_032310.csv\")\n",
    "\n",
    "df['merchDegree'] = df.merchant.apply(add_degree)\n",
    "df['custDegree'] = df.customer.apply(add_degree)\n",
    "df['custPageRank'] = df.customer.apply(add_pagerank)\n",
    "df['merchPageRank'] = df.merchant.apply(add_pagerank)\n",
    "df['merchCommunity'] = df.merchant.apply(add_community)\n",
    "df['custCommunity'] = df.customer.apply(add_community)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test output\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_graph = df.drop('fraud', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_graph[['amount', 'merchDegree', 'custDegree', 'custPageRank', 'merchPageRank']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing \n",
    "The standard features are preprocessed in the same way as before. The PageRank and Degree of both the customer and the merchant are min-max scaled and their community is one-hot encoded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "df[['amount', 'merchDegree', 'custDegree', 'custPageRank', 'merchPageRank']] = scaler.fit_transform(df[['amount', 'merchDegree', 'custDegree', 'custPageRank', 'merchPageRank']])\n",
    "features_graph[['amount', 'merchDegree', 'custDegree', 'custPageRank', 'merchPageRank']] = df[['amount', 'merchDegree', 'custDegree', 'custPageRank', 'merchPageRank']]\n",
    "\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "features_graph.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_graph =  features_graph.drop(['step','zipcodeOri', 'zipMerchant', 'customer'], axis = 1)\n",
    "features_enhanced = pd.get_dummies(features_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_enhanced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training: Network Enhanced vs Standard Model\n",
    "Two models are evaluated using K-fold Cross-Validation: one model trained on the network emnhaced input feature set and one on the standard features. The Random Forest models are initiated with the optimal hyperparameters found using grid search above.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "fold_betas = []\n",
    "fold_accuracy = []\n",
    "kf.get_n_splits(features_final)\n",
    "\n",
    "for train_index, test_index in kf.split(features_final):\n",
    "    X_train_final, X_test_final = features_final.iloc[train_index], features_final.iloc[test_index]\n",
    "    X_train_enh, X_test_enh = features_enhanced.iloc[train_index], features_enhanced.iloc[test_index]\n",
    "    y_train, y_test = label.iloc[train_index], label.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    clf_final = RandomForestClassifier(max_features='sqrt',min_samples_split=50,n_estimators=100)\n",
    "    clf_enh = RandomForestClassifier(max_features='sqrt',min_samples_split=50,n_estimators=100)\n",
    "    \n",
    "    clf_final.fit(X_train_final,y_train)\n",
    "    clf_enh.fit(X_train_enh, y_train)\n",
    "    \n",
    "    predictions_final = clf_final.predict(X_test_final)\n",
    "    predictions_enh = clf_enh.predict(X_test_enh)\n",
    "    \n",
    "    fold_betas.append({\"standard\": fbeta_score( y_test, predictions_final, average='macro', beta=1),\n",
    "                       \"enhanced\": fbeta_score( y_test, predictions_enh, average='macro', beta=1) })\n",
    "    fold_accuracy.append({\"standard\": accuracy_score( y_test, predictions_final),\n",
    "                       \"enhanced\": accuracy_score(y_test, predictions_enh) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"---------- Betas Average ----------\")\n",
    "calculate_average_for_fold(fold_betas, [\"standard\", \"enhanced\"])\n",
    "print(\"---------- Accuracy Averages -----------\")\n",
    "calculate_average_for_fold(fold_accuracy, [\"standard\", \"enhanced\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Evaluation \n",
    "\n",
    "The results will be evaluated with regards to these three factors: \n",
    "* Statistical Accuracy\n",
    "* Interpretability\n",
    "* Operational Efficiency\n",
    "\n",
    "The statistical accuracy will be evaluated by training both the standard and network enhanced model on 100 random train-test splits and creating confidence intervals of the difference in metrics between the two models. \n",
    "\n",
    "The interpretability will be evaluated using the feature importance statistic on the Random Forest model. \n",
    "\n",
    "The operational efficience will be evaluated by calculating the average training and prediction time of the two models over the 100 train-test splits. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the amount of True Positives, True Negatives, False Positives, and False Negatives\n",
    "def calc_metrics(predictions, true_values):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i, true_val in enumerate(true_values): \n",
    "        if true_val==predictions[i]==1:\n",
    "            TP += 1\n",
    "        if predictions[i]==1 and true_val!=predictions[i]:\n",
    "            FP += 1\n",
    "        if true_val==predictions[i]==0:\n",
    "            TN += 1\n",
    "        if predictions[i]==0 and true_val!=predictions[i]:\n",
    "            FN += 1\n",
    "    return {'TP': TP, 'TN': TN, 'FP': FP, 'FN': FN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Function for training and recording the results of both models on a specified random seed. \n",
    "def train_models(seed):\n",
    "    \n",
    "    X_train_std, X_test_std, y_train, y_test = train_test_split(features_final, \n",
    "                                                    label, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = seed)\n",
    "\n",
    "    X_train_enh, X_test_enh, y_train_enh, y_test_enh = train_test_split(features_enhanced, \n",
    "                                                    label, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = seed)\n",
    "    \n",
    "    #TODO: Initialize the classifier\n",
    "    clf_std = RandomForestClassifier(max_features='sqrt',min_samples_split=50,n_estimators=100)\n",
    "    clf_enh = RandomForestClassifier(max_features='sqrt',min_samples_split=50,n_estimators=100)\n",
    "\n",
    "    t0=time.time()\n",
    "    clf_std.fit(X_train_std, y_train)\n",
    "    training_time_std = time.time()-t0 \n",
    "\n",
    "    t1=time.time()\n",
    "    clf_enh.fit(X_train_enh, y_train)\n",
    "    training_time_enh = time.time()-t1 \n",
    "\n",
    "    t2 = time.time()\n",
    "    predictions_std = clf_std.predict(X_test_std)\n",
    "    pred_time_std = time.time()-t2 \n",
    "\n",
    "    t3 = time.time()\n",
    "    predictions_enh = clf_enh.predict(X_test_enh)\n",
    "    pred_time_enh = time.time()-t3 \n",
    "\n",
    "    f1_std = fbeta_score(y_test, predictions_std, beta = 1)\n",
    "    f1_enh = fbeta_score(y_test, predictions_enh, beta = 1)\n",
    "    return {'met_std': calc_metrics(predictions_std, y_test), 'met_enh': calc_metrics(predictions_enh, y_test),\n",
    "            'f1_std': f1_std, 'f1_enh': f1_enh, 'times': {'training_time_std': training_time_std, \n",
    "            'training_time_enh': training_time_enh, 'pred_time_std': pred_time_std, \n",
    "            'pred_time_enh': pred_time_enh}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train 100 models \n",
    "training_seeds_result = []\n",
    "\n",
    "for i in range(100):\n",
    "    training_seeds_result.append(train_models(i))\n",
    "    print(\"----- Training: {} done -----\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savning the results (commented out to not oversave )\n",
    "import pickle\n",
    "\n",
    "with open('training_seeds_result', 'wb') as fp:\n",
    "    pickle.dump(training_seeds_result, fp)\n",
    "\n",
    "# get prediction results of 100 classifiers back\n",
    "#with open ('training_seeds_result', 'rb') as fp:\n",
    "    #training_seeds_result = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_sum_std = 0\n",
    "FP_sum_std = 0\n",
    "TN_sum_std = 0\n",
    "FN_sum_std = 0\n",
    "TP_sum_enh = 0\n",
    "FP_sum_enh = 0\n",
    "TN_sum_enh = 0\n",
    "FN_sum_enh = 0\n",
    "f1_enh_sum = 0\n",
    "f1_std_sum = 0\n",
    "\n",
    "training_time_std_avg = 0\n",
    "training_time_enh_avg = 0\n",
    "pred_time_std_sum_avg = 0\n",
    "pred_time_enh_sum_avg = 0\n",
    "\n",
    "for o in training_seeds_result:\n",
    "    TP_sum_std += o['met_std']['TP']\n",
    "    FP_sum_std += o['met_std']['FP']\n",
    "    TN_sum_std += o['met_std']['TN']\n",
    "    FN_sum_std += o['met_std']['FN']\n",
    "    TP_sum_enh += o['met_enh']['TP']\n",
    "    FP_sum_enh += o['met_enh']['FP']\n",
    "    TN_sum_enh += o['met_enh']['TN']\n",
    "    FN_sum_enh += o['met_enh']['FN']\n",
    "    f1_enh_sum += o['f1_enh']\n",
    "    f1_std_sum += o['f1_std']\n",
    "    \n",
    "    training_time_std_avg += o['times']['training_time_std']/100\n",
    "    training_time_enh_avg += o['times']['training_time_enh']/100\n",
    "    pred_time_std_sum_avg += o['times']['pred_time_std']/100\n",
    "    pred_time_enh_sum_avg += o['times']['pred_time_enh']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- Metric comparison ----------\")\n",
    "print(\"TP_sum_std: {}\".format(TP_sum_std/100.0))\n",
    "print(\"FP_sum_std: {}\".format(FP_sum_std/100.0))\n",
    "print(\"TN_sum_std: {}\".format(TN_sum_std/100.0))\n",
    "print(\"FN_sum_std: {}\".format(FN_sum_std/100.0))\n",
    "print(\"TP_sum_enh: {}\".format(TP_sum_enh/100.0))\n",
    "print(\"FP_sum_enh: {}\".format(FP_sum_enh/100.0))\n",
    "print(\"TN_sum_enh: {}\".format(TN_sum_enh/100.0))\n",
    "print(\"FN_sum_enh: {}\".format(FN_sum_enh/100.0))\n",
    "print(\"f1_enh_sum: {}\".format(f1_enh_sum/100.0))\n",
    "print(\"f1_std_sum: {}\".format(f1_std_sum/100.0))\n",
    "print(\"---------- Time Evaluation ----------\")\n",
    "print('training_time_std: {}'.format(training_time_std_avg))\n",
    "print('training_time_enh {}:'.format(training_time_enh_avg))\n",
    "print('pred_time_std {}:'.format(pred_time_std_sum_avg))\n",
    "print('pred_time_enh {}:'.format(pred_time_enh_sum_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "Using the feature importance statistic on the random forest model the most important features of the model can be plotted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enh, X_test_enh, y_train_enh, y_test_enh = train_test_split(features_enhanced, \n",
    "                                                    label, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "clf_enh = RandomForestClassifier(max_features='sqrt',min_samples_split=50,n_estimators=100)\n",
    "clf_enh.fit(X_train_enh, y_train_enh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams.update({'font.size': 22})\n",
    "importances = clf_enh.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf_enh.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    " \n",
    "\n",
    "\n",
    "plt.figure(figsize=(24,5))\n",
    "plt.xlabel(\"Feature Name\", fontsize=30)\n",
    "plt.ylabel(\"Importance \", fontsize=30)\n",
    "plt.bar(range(5), importances[indices[0:5]],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(5), features_enhanced.columns[indices[0:5]].get_values())\n",
    "plt.xlim([-1, 5])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(24,5))\n",
    "plt.xlabel(\"Feature\", fontsize=30)\n",
    "plt.ylabel(\"Importance\", fontsize=30)\n",
    "plt.plot(range(X_train_enh.shape[1]), importances[indices],\n",
    "       color=\"r\")\n",
    "\n",
    "plt.xlim([-1, X_train_enh.shape[1]])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the two plots above the amount feature is by far the most important feature. Interstingly though the other four on the top five features are all derived from the graph. \n",
    "\n",
    "### Statistic Significance \n",
    "To evaluate the statistical significance of the resuilst. The difference in results between the two models will be calculated and used to create 99% confidence intervals for the improvements of the network enhanced model. The improvement is considered significant if 0 is not present in the interval.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results_lists = {\n",
    "    'TP_std' : [],\n",
    "    'FP_std' : [],\n",
    "    'TN_std' : [],\n",
    "    'FN_std' : [],\n",
    "    'TP_enh' : [],\n",
    "    'FP_enh' : [],\n",
    "    'TN_enh' : [],\n",
    "    'FN_enh' : [],\n",
    "    'f1_enh' : [],\n",
    "    'f1_std' : []\n",
    "}\n",
    "\n",
    "\n",
    "for o in training_seeds_result:\n",
    "    training_results_lists['TP_std'].append(o['met_std']['TP'])\n",
    "    training_results_lists['FP_std'].append(o['met_std']['FP'])\n",
    "    training_results_lists['TN_std'].append(o['met_std']['TN'])\n",
    "    training_results_lists['FN_std'].append(o['met_std']['FN'])\n",
    "    training_results_lists['TP_enh'].append(o['met_enh']['TP'])\n",
    "    training_results_lists['FP_enh'].append(o['met_enh']['FP'])\n",
    "    training_results_lists['TN_enh'].append(o['met_enh']['TN'])\n",
    "    training_results_lists['FN_enh'].append(o['met_enh']['FN'])\n",
    "    training_results_lists['f1_enh'].append(o['f1_enh'])\n",
    "    training_results_lists['f1_std'].append(o['f1_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in training_results_lists:\n",
    "    temp_array = np.array(training_results_lists[val])\n",
    "    training_results_lists[val] = temp_array\n",
    "    \n",
    "    print(\"{}: avg: {} std: {}\".format(val, temp_array.mean(), temp_array.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.stats\n",
    "\n",
    "# Helper function to create confidence intervals \n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0*np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
    "    return m, m-h, m+h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = ['f1', 'TP', 'TN', 'FP', 'FN']\n",
    "\n",
    "for test in tests:\n",
    "    mean, lower, upper = mean_confidence_interval(\n",
    "        training_results_lists['{}_enh'.format(test)] - training_results_lists['{}_std'.format(test)],\n",
    "        confidence=0.99)\n",
    "    print(\"Test {},  lower: {}, mean:{} upper: {}\".format(test,  lower, mean, upper))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
